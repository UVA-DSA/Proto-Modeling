{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/home/tay/anaconda3/envs/py2_NIST/lib/python27.zip',\n",
       " '/home/tay/anaconda3/envs/py2_NIST/lib/python2.7',\n",
       " '/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/plat-linux2',\n",
       " '/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/lib-tk',\n",
       " '/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/lib-old',\n",
       " '/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/lib-dynload',\n",
       " '/home/tay/.local/lib/python2.7/site-packages',\n",
       " '/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/site-packages',\n",
       " '/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/site-packages/IPython/extensions',\n",
       " '/home/tay/.ipython',\n",
       " '/home/tay/Documents/DSA-NIST/NIST_Utils-master/pymetamap']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/NIST_Utils-master/pymetamap\")\n",
    "sys.path\n",
    "#/home/tay/Documents/DSA-NIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (ConceptExtract.py, line 271)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"ConceptExtract.py\"\u001b[0;36m, line \u001b[0;32m271\u001b[0m\n\u001b[0;31m    if len(value) > 0:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from NLPutils import NLPutils as NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.snowball import EnglishStemmer # load the stemmer module from NLTK\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import make_scorer\n",
    "import pickle\n",
    "import math\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import py_trees\n",
    "import pymetamap #**\n",
    "import behaviours as be #** be sure to properly map pymetampap -> try in VM\n",
    "    ### make sure to include behaviours_m.py instead of behaviors.py\n",
    "from py_trees.blackboard import Blackboard\n",
    "from scipy import spatial\n",
    "from pandas import DataFrame\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAAdata(object):\n",
    "    def __init__(self,text,vital,inter):\n",
    "        self.text = text\n",
    "        self.vital = vital\n",
    "        self.inter = inter\n",
    "        \n",
    "def load_RAA_data(path, cv = True): \n",
    "    df = pd.read_excel(path)\n",
    "    interset = set()\n",
    "    interdict = dict()\n",
    "    narratives = df['Narrative']\n",
    "    narratives = [i for i in narratives]\n",
    "    inters = df['Interventions']\n",
    "    vitals = df['Vitals']\n",
    "    vitals = [i for i in vitals]\n",
    "    interventions = []\n",
    "    for item in inters:\n",
    "        inter = item.strip('{}').split('}{')\n",
    "        inter = [i.split(':')[-1].strip().lower() for i in inter]\n",
    "        c_int = []\n",
    "        for j in inter:\n",
    "            interset.add(j)\n",
    "            if j in interdict:\n",
    "                interdict[j] += 1\n",
    "            else:\n",
    "                interdict[j] = 1\n",
    "            c_int.append(j)\n",
    "        interventions.append(c_int)\n",
    "    for inter in list(interdict):\n",
    "        if cv and interdict[inter] < 20: del interdict[inter]\n",
    "    data = [RAAdata(item,vitals[idx],interventions[idx]) for idx,item in enumerate(narratives)]\n",
    "    \n",
    "    return data,interdict\n",
    "\n",
    "def fullmatch(regex, string, flags=0):\n",
    "    \"\"\"Emulate python-3.4 re.fullmatch().\"\"\"\n",
    "    return re.match(\"(?:\" + regex + r\")\\Z\", string, flags=flags)\n",
    "\n",
    "# preprocess utils\n",
    "def cleanHtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext\n",
    "\n",
    "def cleanPunc(sentence):\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "\n",
    "def keepAlpha(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "\n",
    "def weighted_precision_recall_f1_util (y_test, y_pre, weight = None):\n",
    "    tp, fp, fn = [0. for _ in range(len(y_pre[0]))], [0. for _ in range(len(y_pre[0]))], \\\n",
    "    [0. for _ in range(len(y_pre[0]))]\n",
    "    for idx in range(len(y_pre)):\n",
    "        for i in range(len(y_pre[idx])):\n",
    "            if y_pre[idx][i] == 1 and y_test[idx][i] == 1: tp[i] += 1\n",
    "            elif y_pre[idx][i] == 1 and y_test[idx][i] == 0: fp[i] += 1\n",
    "            elif y_pre[idx][i] == 0 and y_test[idx][i] == 1: fn[i] += 1\n",
    "    precision = [tp[i] / (tp[i] + fp[i]) if tp[i] > 0 or fp[i] > 0 else 0. for i in range(len(tp))]\n",
    "    recall = [tp[i] / (tp[i] + fn[i]) if tp[i] > 0 or fn[i] > 0 else 0. for i in range(len(tp))]\n",
    "    f1 = [2 * precision[i] * recall[i] / (precision[i] + recall[i]) \\\n",
    "         if precision[i] > 0 or recall[i] > 0 else 0. for i in range(len(tp))]\n",
    "    return np.average(precision, weights = weight), np.average(recall, weights = weight), \\\n",
    "np.average(f1, weights = weight)\n",
    "\n",
    "def weighted_precision (y_test, y_pre, weight = None):\n",
    "    precision, _, _ = weighted_precision_recall_f1_util (y_test, y_pre, weight)\n",
    "    return precision\n",
    "\n",
    "def weighted_recall (y_test, y_pre, weight = None):\n",
    "    _, recall, _ = weighted_precision_recall_f1_util (y_test, y_pre, weight)\n",
    "    return recall\n",
    "\n",
    "def weighted_f1 (y_test, y_pre, weight = None):\n",
    "    _, _, f1 = weighted_precision_recall_f1_util (y_test, y_pre, weight)\n",
    "    return f1\n",
    "\n",
    "def show_results(scores):\n",
    "    metrics = ['test_precision_weighted','test_recall_weighted', 'test_f1_weighted',\\\n",
    "            'test_precision_micro', 'test_recall_micro', 'test_f1_micro']\n",
    "    for metric in metrics:\n",
    "        print metric + ':' + '%.2f' % np.average(scores[metric])\n",
    "        \n",
    "def risk_factor(gt, probs, preds):\n",
    "    risk = []\n",
    "    for idx,case in enumerate(probs):\n",
    "        r = 0\n",
    "        for i,prob in enumerate(case):\n",
    "            if preds[idx][i] == 1 and gt[idx][i] == 0:\n",
    "                r += prob * int2fp_score[num2int[i]] / sum(gt[idx])\n",
    "            if preds[idx][i] == 0 and gt[idx][i] == 1:\n",
    "                r += prob * int2fn_score[num2int[i]] / sum(gt[idx])\n",
    "        risk.append(r)\n",
    "    return sum(risk) / len(risk)\n",
    "\n",
    "def trans_prob(probs):\n",
    "    transed_prob = [[0.] * len(probs) for _ in range(len(probs[0]))]\n",
    "    for idx, res in enumerate(probs):\n",
    "        for i, p in enumerate(res):\n",
    "            if len(p) < 2: transed_prob[i][idx] = 1. - p[0]\n",
    "            else: transed_prob[i][idx] = p[1]\n",
    "                \n",
    "    return transed_prob\n",
    "\n",
    "def show_test_results(gt, res, prob, class_weight):\n",
    "    print \"precision_micro\" + ':' + '%.2f' % precision_score(gt, res, average = 'micro')\n",
    "    print \"recall_micro\" + ':' + '%.2f' % recall_score(gt, res, average = 'micro')\n",
    "    print \"f1_micro\" + ':' + '%.2f' % f1_score(gt, res, average = 'micro')\n",
    "    print \"precision_weighted\" + ':' + '%.2f' % weighted_precision(gt, res, class_weight)\n",
    "    print \"recall_weighted\" + ':' + '%.2f' % weighted_recall(gt, res, class_weight)\n",
    "    print \"f1_weighted\" + ':' + '%.2f' % weighted_f1(gt, res, class_weight)\n",
    "    print \"risk_factor\" + ':' + '%.4f' % risk_factor(gt, prob, res)\n",
    "    \n",
    "def filtering(res, prob, threshold):\n",
    "    for idx, case in enumerate(res):\n",
    "        for i in range(len(case)):\n",
    "            if prob[idx][i] < threshold:\n",
    "                res[idx][i] = 0\n",
    "                prob[idx][i] = 0.\n",
    "    return res, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read labeled cases\n",
    "docu = './RAA_train.xlsx'\n",
    "df = pd.read_excel(docu)\n",
    "vitals = df['Vitals']\n",
    "train_narratives = df['Narrative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Declare RAA data object \n",
    "#then call your object functions corectly for vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##SKIP##\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "# EKGset = set()\n",
    "# train_vec = []\n",
    "# EKGdic = {\n",
    "#      '':'',\n",
    "#      'AV_Block_1st_Deg':'AV_Block-1st_Degree',\n",
    "#      'AV_Block_1st_Degree':'AV_Block-1st_Degree',\n",
    "#      'AV_Block_2nd_Degree_Type_1':'AV_Block_2nd_Degree_Type_1',\n",
    "#      'AV_Block_2nd_Degree_Type_2':'AV_Block_2nd_Degree_Type_2',\n",
    "#      'AV_Block_3rd_Degree':'AV_Block_3rd_Degree',\n",
    "#      'Asystole':'Asystole',\n",
    "#      'Artifact':'Artifact',\n",
    "#      'Atrial_Fibrill':'Atrial_Fibrillation',\n",
    "#      'Atrial_Fibrillation':'Atrial_Fibrillation',\n",
    "#      'Atrial_Flutter':'Atrial_Flutter',\n",
    "#      'Agonal/Idioventricular':'Agonal/Idioventricular',\n",
    "#      'Juncti':'Junctional_Rhythm',\n",
    "#      'Junctiona':'Junctional_Rhythm',\n",
    "#      'Junctional':'Junctional_Rhythm',\n",
    "#      'Non_STEMI_Anterior_Ischemia':'Non_STEMI_Anterior_Ischemia',\n",
    "#      'Non_STEMI_Lateral_Ischemia':'Non_STEMI_Lateral_Ischemia',\n",
    "#      'Other_(Not_Listed)':'Other_(Not_Listed)',\n",
    "#      'P': 'Paced_Rhythm',\n",
    "#      'PEA':'Pulseless_Electrical_Activity',\n",
    "#      'Pac':'Paced_Rhythm',\n",
    "#      'Paced':'Paced_Rhythm',\n",
    "#      'Paced_Rhythm':'Paced_Rhythm',\n",
    "#      'Premature_Ventricular_Contractions':'Premature_Ventricular_Contractions',\n",
    "#      'Premature_Atrial_Contractions':'Premature_Atrial_Contractions',\n",
    "#      'Right_Bundle_Branch_Block':'Right_Bundle_Branch_Block',\n",
    "#      'Left_Bundle_Branch_Block':'Left_Bundle_Branch_Block',\n",
    "#      'STEMI_Anterior_Ischemia':'STEMI_Anterior_Ischemia',\n",
    "#      'STEMI_Lateral_Ischemia':'STEMI_Lateral_Ischemia',\n",
    "#      'STEMI_Inferior_Ischemia':'STEMI_Inferior_Ischemia',\n",
    "#      'S':'Sinus_Rhythm',\n",
    "#      'Si':'Sinus_Rhythm',\n",
    "#      'Sin':'Sinus_Rhythm',\n",
    "#      'Sinu':'Sinus_Rhythm',\n",
    "#      'Sinus':'Sinus_Rhythm',\n",
    "#      'Sinus_':'Sinus_Rhythm',\n",
    "#      'Sinus_Arrhythmia':'Sinus_Arrhythmia',\n",
    "#      'Sinus_Bradycardia':'Sinus_Bradycardia',\n",
    "#      'Sinus_R':'Sinus_Rhythm',\n",
    "#      'Sinus_Rh':'Sinus_Rhythm',\n",
    "#      'Sinus_Rhy':'Sinus_Rhythm',\n",
    "#      'Sinus_Rhyt':'Sinus_Rhythm',\n",
    "#      'Sinus_Rhyth':'Sinus_Rhythm',\n",
    "#      'Sinus_Rhythm':'Sinus_Rhythm',\n",
    "#      'Sinus_Rhythm,Sinus_Tachycardia':'Sinus_Rhythm,Sinus_Tachycardia',\n",
    "#      'Sinus_T':'Sinus_Tachycardia',\n",
    "#      'Sinus_Tach':'Sinus_Tachycardia',\n",
    "#      'Sinus_Tachyc':'Sinus_Tachycardia',\n",
    "#      'Sinus_Tachycardi':'Sinus_Tachycardia',\n",
    "#      'Sinus_Tachycardia':'Sinus_Tachycardia',\n",
    "#      'Supravent':'Supraventricular_Tachycardia',\n",
    "#      'Supraventricular_Tachycardia':'Supraventricular_Tachycardia',\n",
    "#      'Torsades_De_Points':'Torsades_De_Points',\n",
    "#      'Ventricular_Fibrillation':'Ventricular_Fibrillation',\n",
    "#      'Ventricular_Tachycardia_(With_Pulse)':'Ventricular_Tachycardia',\n",
    "#      'Ventricular_Tachycardia_(Pulseless)':'Ventricular_Tachycardia_(Pulseless)',\n",
    "#      'Unknown_AED_Non_Shockable_Rhythm':'Unknown_AED_Non_Shockable_Rhythm'\n",
    "    \n",
    "# }\n",
    "# # extract concept and calculate similarity\n",
    "# from ranking_func import rank\n",
    "# pool = set(['Medical - Abdominal Pain',\n",
    "#             'Medical - Altered Mental Status',\n",
    "#             'Medical - Seizure',\n",
    "#             'Medical - Respiratory Distress/Asthma/COPD/Croup/Reactive Airway',\n",
    "#             'General - Behavioral/Patient Restraint',\n",
    "#             'Medical - Overdose/Poisoning - Opioid',\n",
    "#             'Medical - Diabetic - Hypoglycemia',\n",
    "#             'Medical - Chest Pain - Cardiac Suspected'])\n",
    "\n",
    "# def pre_tick_handler(behaviour_tree):\n",
    "#     blackboard = Blackboard()\n",
    "#     blackboard.tick_num += 1\n",
    "    \n",
    "# pt = 0\n",
    "\n",
    "\n",
    "# #for i,item in enumerate(tqdm(train_narratives)): *** Update jupyter notebook ***\n",
    "# for i,item in enumerate((train_narratives)):\n",
    "#     if (True) :\n",
    "#         if not pd.isnull(vitals[i]):\n",
    "#             vt = vitals[i].strip('{}').split('}{')\n",
    "#             vt = [it.split(':')[-1] for it in vt]\n",
    "#             for idx,it in enumerate(vt):\n",
    "#                 if 'EKG-' in it:\n",
    "#                     temp = it.split('EKG-')\n",
    "#                     temp[1] = temp[1].replace(' ','_')\n",
    "#                     temp[1] = temp[1].replace('-','_')\n",
    "#                     if ',' in temp[1]:\n",
    "#                         t = temp[1].split(',')\n",
    "#                         t = [EKGdic[i] for i in t]\n",
    "#                         vt[idx] = temp[0] + 'EKG-' + ','.join(t)\n",
    "#                     else:\n",
    "#                         vt[idx] = temp[0] + 'EKG-' + EKGdic[temp[1]]\n",
    "#                     if len(temp[1]) > 0:\n",
    "#                         EKGset.add(temp[1])\n",
    "#             vt = [ite for l in vt for ite in l.strip().split(' ')]\n",
    "#             for idx in xrange(len(vt)):\n",
    "#                 if idx < len(vt) and '-' not in vt[idx]:\n",
    "#                     vt.pop(idx)\n",
    "#             for idx,it in enumerate(vt):\n",
    "#                 temp = it.split('-')\n",
    "#                 vt[idx] = (temp[0],temp[1])\n",
    "#     blackboard = Blackboard()\n",
    "#     blackboard.text = [item]\n",
    "#     root = py_trees.composites.Sequence(\"Root_1\")\n",
    "#     IG = be.InformationGathering(inC = vt)\n",
    "#     TC = be.TextCollection()\n",
    "#     V = be.Vectorize()\n",
    "#     root.add_children([TC,IG,V])\n",
    "#     behaviour_tree = py_trees.trees.BehaviourTree(root)\n",
    "#     behaviour_tree.add_pre_tick_handler(pre_tick_handler)\n",
    "#     behaviour_tree.setup(15)\n",
    "#     behaviour_tree.tick_tock(\n",
    "#             sleep_ms=50,\n",
    "#             number_of_iterations=1,\n",
    "#             pre_tick_handler=None,\n",
    "#        post_tick_handler=None\n",
    "#     )\n",
    "#     pt = i\n",
    "#     train_vec.append(blackboard.TV)\n",
    "#     with open('train_vec.txt', 'w') as f:\n",
    "#         pickle.dump(blackboard.TV, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('train_vec_list.txr','w') as fo:\n",
    "#     pickle.dump(train_vec, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('train_vec_list.txr') as fo:\n",
    "#     train_vec = pickle.load(fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docu = './RAA_1000_test.xlsx'\n",
    "df = pd.read_excel(docu)\n",
    "vitals = df['Vitals']\n",
    "test_narratives = df['Narrative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm_notebook as tqdm\n",
    "# EKGset = set()\n",
    "# test_vec = []\n",
    "# EKGdic = {\n",
    "#      '':'',\n",
    "#      'AV_Block_1st_Deg':'AV_Block-1st_Degree',\n",
    "#      'AV_Block_1st_Degree':'AV_Block-1st_Degree',\n",
    "#      'AV_Block_2nd_Degree_Type_1':'AV_Block_2nd_Degree_Type_1',\n",
    "#      'AV_Block_2nd_Degree_Type_2':'AV_Block_2nd_Degree_Type_2',\n",
    "#      'AV_Block_3rd_Degree':'AV_Block_3rd_Degree',\n",
    "#      'Asystole':'Asystole',\n",
    "#      'Artifact':'Artifact',\n",
    "#      'Atrial_Fibrill':'Atrial_Fibrillation',\n",
    "#      'Atrial_Fibrillation':'Atrial_Fibrillation',\n",
    "#      'Atrial_Flutter':'Atrial_Flutter',\n",
    "#      'Agonal/Idioventricular':'Agonal/Idioventricular',\n",
    "#      'Juncti':'Junctional_Rhythm',\n",
    "#      'Junctiona':'Junctional_Rhythm',\n",
    "#      'Junctional':'Junctional_Rhythm',\n",
    "#      'Non_STEMI_Anterior_Ischemia':'Non_STEMI_Anterior_Ischemia',\n",
    "#      'Non_STEMI_Lateral_Ischemia':'Non_STEMI_Lateral_Ischemia',\n",
    "#      'Other_(Not_Listed)':'Other_(Not_Listed)',\n",
    "#      'P': 'Paced_Rhythm',\n",
    "#      'PEA':'Pulseless_Electrical_Activity',\n",
    "#      'Pac':'Paced_Rhythm',\n",
    "#      'Paced':'Paced_Rhythm',\n",
    "#      'Paced_Rhythm':'Paced_Rhythm',\n",
    "#      'Premature_Ventricular_Contractions':'Premature_Ventricular_Contractions',\n",
    "#      'Premature_Atrial_Contractions':'Premature_Atrial_Contractions',\n",
    "#      'Right_Bundle_Branch_Block':'Right_Bundle_Branch_Block',\n",
    "#      'Left_Bundle_Branch_Block':'Left_Bundle_Branch_Block',\n",
    "#      'STEMI_Anterior_Ischemia':'STEMI_Anterior_Ischemia',\n",
    "#      'STEMI_Lateral_Ischemia':'STEMI_Lateral_Ischemia',\n",
    "#      'STEMI_Inferior_Ischemia':'STEMI_Inferior_Ischemia',\n",
    "#      'S':'Sinus_Rhythm',\n",
    "#      'Si':'Sinus_Rhythm',\n",
    "#      'Sin':'Sinus_Rhythm',\n",
    "#      'Sinu':'Sinus_Rhythm',\n",
    "#      'Sinus':'Sinus_Rhythm',\n",
    "#      'Sinus_':'Sinus_Rhythm',\n",
    "#      'Sinus_Arrhythmia':'Sinus_Arrhythmia',\n",
    "#      'Sinus_Bradycardia':'Sinus_Bradycardia',\n",
    "#      'Sinus_R':'Sinus_Rhythm',\n",
    "#      'Sinus_Rh':'Sinus_Rhythm',\n",
    "#      'Sinus_Rhy':'Sinus_Rhythm',\n",
    "#      'Sinus_Rhyt':'Sinus_Rhythm',\n",
    "#      'Sinus_Rhyth':'Sinus_Rhythm',\n",
    "#      'Sinus_Rhythm':'Sinus_Rhythm',\n",
    "#      'Sinus_Rhythm,Sinus_Tachycardia':'Sinus_Rhythm,Sinus_Tachycardia',\n",
    "#      'Sinus_T':'Sinus_Tachycardia',\n",
    "#      'Sinus_Tach':'Sinus_Tachycardia',\n",
    "#      'Sinus_Tachyc':'Sinus_Tachycardia',\n",
    "#      'Sinus_Tachycardi':'Sinus_Tachycardia',\n",
    "#      'Sinus_Tachycardia':'Sinus_Tachycardia',\n",
    "#      'Supravent':'Supraventricular_Tachycardia',\n",
    "#      'Supraventricular_Tachycardia':'Supraventricular_Tachycardia',\n",
    "#      'Torsades_De_Points':'Torsades_De_Points',\n",
    "#      'Ventricular_Fibrillation':'Ventricular_Fibrillation',\n",
    "#      'Ventricular_Tachycardia_(With_Pulse)':'Ventricular_Tachycardia',\n",
    "#      'Ventricular_Tachycardia_(Pulseless)':'Ventricular_Tachycardia_(Pulseless)',\n",
    "#      'Unknown_AED_Non_Shockable_Rhythm':'Unknown_AED_Non_Shockable_Rhythm'\n",
    "    \n",
    "# }\n",
    "# # extract concept and calculate similarity\n",
    "# from ranking_func import rank\n",
    "# pool = set(['Medical - Abdominal Pain',\n",
    "#             'Medical - Altered Mental Status',\n",
    "#             'Medical - Seizure',\n",
    "#             'Medical - Respiratory Distress/Asthma/COPD/Croup/Reactive Airway',\n",
    "#             'General - Behavioral/Patient Restraint',\n",
    "#             'Medical - Overdose/Poisoning - Opioid',\n",
    "#             'Medical - Diabetic - Hypoglycemia',\n",
    "#             'Medical - Chest Pain - Cardiac Suspected'])\n",
    "\n",
    "# def pre_tick_handler(behaviour_tree):\n",
    "#     blackboard = Blackboard()\n",
    "#     blackboard.tick_num += 1\n",
    "    \n",
    "# pt = 0\n",
    "\n",
    "# #for i,item in enumerate(tqdm(train_narratives)): *** Update jupyter notebook ***\n",
    "# for i,item in enumerate((test_narratives[1:100])):\n",
    "#     if not pd.isnull(vitals[i]):\n",
    "#         vt = vitals[i].strip('{}').split('}{')\n",
    "#         vt = [it.split(':')[-1] for it in vt]\n",
    "#         for idx,it in enumerate(vt):\n",
    "#             if 'EKG-' in it:\n",
    "#                 temp = it.split('EKG-')\n",
    "#                 temp[1] = temp[1].replace(' ','_')\n",
    "#                 temp[1] = temp[1].replace('-','_')\n",
    "#                 if ',' in temp[1]:\n",
    "#                     t = temp[1].split(',')\n",
    "#                     t = [EKGdic[i] for i in t]\n",
    "#                     vt[idx] = temp[0] + 'EKG-' + ','.join(t)\n",
    "#                 else:\n",
    "#                     vt[idx] = temp[0] + 'EKG-' + EKGdic[temp[1]]\n",
    "#                 if len(temp[1]) > 0:\n",
    "#                     EKGset.add(temp[1])\n",
    "#         vt = [ite for l in vt for ite in l.strip().split(' ')]\n",
    "#         for idx in xrange(len(vt)):\n",
    "#             if idx < len(vt) and '-' not in vt[idx]:\n",
    "#                 vt.pop(idx)\n",
    "#         for idx,it in enumerate(vt):\n",
    "#             temp = it.split('-')\n",
    "#             vt[idx] = (temp[0],temp[1])\n",
    "#     print('VT length',len(vt))\n",
    "#     blackboard = Blackboard()\n",
    "#     blackboard.text = [item]\n",
    "#     root = py_trees.composites.Sequence(\"Root_1\")\n",
    "#     #IG = be.InformationGathering(inC = vt)\n",
    "#     IG = be.InformationGathering()\n",
    "#     TC = be.TextCollection()\n",
    "#     V = be.Vectorize()\n",
    "#     root.add_children([TC,IG,V])\n",
    "#     behaviour_tree = py_trees.trees.BehaviourTree(root)\n",
    "#     behaviour_tree.add_pre_tick_handler(pre_tick_handler)\n",
    "#     behaviour_tree.setup(15)\n",
    "# #     behaviour_tree.tick_tock(\n",
    "# #             sleep_ms=50,\n",
    "# #             number_of_iterations=1,\n",
    "# #             pre_tick_handler=None,\n",
    "# #        post_tick_handler=None\n",
    "# #     )\n",
    "#     print\n",
    "#     print('##### Item', i)\n",
    "#     print('S&S:')\n",
    "#     #print(\"IG: \", IG.sce.Status)\n",
    "# #     for i in blackboard.Inters:\n",
    "# #             print(\"BB S&S: \", i)\n",
    "#     #print(\"IG: \", IG.sce.Status)\n",
    "#     #print(\"SCE.concepts: \", IG.sce.concepts) #Empty []\n",
    "#     #print(\"VCE.concepts: \", IG.vce.concepts) #Empty []\n",
    "#     #IG.sce.DisplayStatus()\n",
    "#     #print('Vital:')\n",
    "# #     IG.vce.DisplayStatus()\n",
    "# #     print(\"IG VCE status: \", IG.vce.Status)\n",
    "#     #print('Inters:')\n",
    "#     #IG.ice.DisplayStatus()\n",
    "#     #print(\"IG SCE Status: \", IG.sce.Status)\n",
    "#     #print(\"TC: \", TC)\n",
    "#     #print(\"V: \", V)\n",
    "#     #print(\"blackboard.TV\", blackboard.TV)\n",
    "#     pt = i\n",
    "#     test_vec.append(blackboard.TV)\n",
    "#     #with open('test_vec.txt', 'w') as f:\n",
    "#        # pickle.dump(blackboard.TV, f)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "EKGset = set()\n",
    "test_vec = []\n",
    "EKGdic = {\n",
    "     '':'',\n",
    "     'AV_Block_1st_Deg':'AV_Block-1st_Degree',\n",
    "     'AV_Block_1st_Degree':'AV_Block-1st_Degree',\n",
    "     'AV_Block_2nd_Degree_Type_1':'AV_Block_2nd_Degree_Type_1',\n",
    "     'AV_Block_2nd_Degree_Type_2':'AV_Block_2nd_Degree_Type_2',\n",
    "     'AV_Block_3rd_Degree':'AV_Block_3rd_Degree',\n",
    "     'Asystole':'Asystole',\n",
    "     'Artifact':'Artifact',\n",
    "     'Atrial_Fibrill':'Atrial_Fibrillation',\n",
    "     'Atrial_Fibrillation':'Atrial_Fibrillation',\n",
    "     'Atrial_Flutter':'Atrial_Flutter',\n",
    "     'Agonal/Idioventricular':'Agonal/Idioventricular',\n",
    "     'Juncti':'Junctional_Rhythm',\n",
    "     'Junctiona':'Junctional_Rhythm',\n",
    "     'Junctional':'Junctional_Rhythm',\n",
    "     'Non_STEMI_Anterior_Ischemia':'Non_STEMI_Anterior_Ischemia',\n",
    "     'Non_STEMI_Lateral_Ischemia':'Non_STEMI_Lateral_Ischemia',\n",
    "     'Other_(Not_Listed)':'Other_(Not_Listed)',\n",
    "     'P': 'Paced_Rhythm',\n",
    "     'PEA':'Pulseless_Electrical_Activity',\n",
    "     'Pac':'Paced_Rhythm',\n",
    "     'Paced':'Paced_Rhythm',\n",
    "     'Paced_Rhythm':'Paced_Rhythm',\n",
    "     'Premature_Ventricular_Contractions':'Premature_Ventricular_Contractions',\n",
    "     'Premature_Atrial_Contractions':'Premature_Atrial_Contractions',\n",
    "     'Right_Bundle_Branch_Block':'Right_Bundle_Branch_Block',\n",
    "     'Left_Bundle_Branch_Block':'Left_Bundle_Branch_Block',\n",
    "     'STEMI_Anterior_Ischemia':'STEMI_Anterior_Ischemia',\n",
    "     'STEMI_Lateral_Ischemia':'STEMI_Lateral_Ischemia',\n",
    "     'STEMI_Inferior_Ischemia':'STEMI_Inferior_Ischemia',\n",
    "     'S':'Sinus_Rhythm',\n",
    "     'Si':'Sinus_Rhythm',\n",
    "     'Sin':'Sinus_Rhythm',\n",
    "     'Sinu':'Sinus_Rhythm',\n",
    "     'Sinus':'Sinus_Rhythm',\n",
    "     'Sinus_':'Sinus_Rhythm',\n",
    "     'Sinus_Arrhythmia':'Sinus_Arrhythmia',\n",
    "     'Sinus_Bradycardia':'Sinus_Bradycardia',\n",
    "     'Sinus_R':'Sinus_Rhythm',\n",
    "     'Sinus_Rh':'Sinus_Rhythm',\n",
    "     'Sinus_Rhy':'Sinus_Rhythm',\n",
    "     'Sinus_Rhyt':'Sinus_Rhythm',\n",
    "     'Sinus_Rhyth':'Sinus_Rhythm',\n",
    "     'Sinus_Rhythm':'Sinus_Rhythm',\n",
    "     'Sinus_Rhythm,Sinus_Tachycardia':'Sinus_Rhythm,Sinus_Tachycardia',\n",
    "     'Sinus_T':'Sinus_Tachycardia',\n",
    "     'Sinus_Tach':'Sinus_Tachycardia',\n",
    "     'Sinus_Tachyc':'Sinus_Tachycardia',\n",
    "     'Sinus_Tachycardi':'Sinus_Tachycardia',\n",
    "     'Sinus_Tachycardia':'Sinus_Tachycardia',\n",
    "     'Supravent':'Supraventricular_Tachycardia',\n",
    "     'Supraventricular_Tachycardia':'Supraventricular_Tachycardia',\n",
    "     'Torsades_De_Points':'Torsades_De_Points',\n",
    "     'Ventricular_Fibrillation':'Ventricular_Fibrillation',\n",
    "     'Ventricular_Tachycardia_(With_Pulse)':'Ventricular_Tachycardia',\n",
    "     'Ventricular_Tachycardia_(Pulseless)':'Ventricular_Tachycardia_(Pulseless)',\n",
    "     'Unknown_AED_Non_Shockable_Rhythm':'Unknown_AED_Non_Shockable_Rhythm'\n",
    "    \n",
    "}\n",
    "# extract concept and calculate similarity\n",
    "from ranking_func import rank\n",
    "pool = set(['Medical - Abdominal Pain',\n",
    "            'Medical - Altered Mental Status',\n",
    "            'Medical - Seizure',\n",
    "            'Medical - Respiratory Distress/Asthma/COPD/Croup/Reactive Airway',\n",
    "            'General - Behavioral/Patient Restraint',\n",
    "            'Medical - Overdose/Poisoning - Opioid',\n",
    "            'Medical - Diabetic - Hypoglycemia',\n",
    "            'Medical - Chest Pain - Cardiac Suspected'])\n",
    "\n",
    "def pre_tick_handler(behaviour_tree):\n",
    "    blackboard = Blackboard()\n",
    "    blackboard.tick_num += 1\n",
    "    \n",
    "pt = 0\n",
    "\n",
    "#for i,item in enumerate(tqdm(train_narratives)): *** Update jupyter notebook ***\n",
    "for i,item in enumerate((test_narratives[1:100])):\n",
    "    if not pd.isnull(vitals[i]):\n",
    "        vt = vitals[i].strip('{}').split('}{')\n",
    "        vt = [it.split(':')[-1] for it in vt]\n",
    "        for idx,it in enumerate(vt):\n",
    "            if 'EKG-' in it:\n",
    "                temp = it.split('EKG-')\n",
    "                temp[1] = temp[1].replace(' ','_')\n",
    "                temp[1] = temp[1].replace('-','_')\n",
    "                if ',' in temp[1]:\n",
    "                    t = temp[1].split(',')\n",
    "                    t = [EKGdic[i] for i in t]\n",
    "                    vt[idx] = temp[0] + 'EKG-' + ','.join(t)\n",
    "                else:\n",
    "                    vt[idx] = temp[0] + 'EKG-' + EKGdic[temp[1]]\n",
    "                if len(temp[1]) > 0:\n",
    "                    EKGset.add(temp[1])\n",
    "        vt = [ite for l in vt for ite in l.strip().split(' ')]\n",
    "        for idx in xrange(len(vt)):\n",
    "            if idx < len(vt) and '-' not in vt[idx]:\n",
    "                vt.pop(idx)\n",
    "        for idx,it in enumerate(vt):\n",
    "            temp = it.split('-')\n",
    "            vt[idx] = (temp[0],temp[1])\n",
    "    blackboard = Blackboard()\n",
    "    blackboard.text = [item]\n",
    "    root = py_trees.composites.Sequence(\"Root_1\")\n",
    "#     IG = be.InformationGathering(inC = vt)\n",
    "    IG = be.InformationGathering(item)\n",
    "    #IG.sce.concepts\n",
    "    #be.IG.update()\n",
    "    TC = be.TextCollection()\n",
    "    V = be.Vectorize()\n",
    "    root.add_children([TC,IG,V])\n",
    "    behaviour_tree = py_trees.trees.BehaviourTree(root)\n",
    "    behaviour_tree.add_pre_tick_handler(pre_tick_handler)\n",
    "    behaviour_tree.setup(15)\n",
    "#     behaviour_tree.tick_tock(\n",
    "#             sleep_ms=50,\n",
    "#             number_of_iterations=1,\n",
    "#             pre_tick_handler=None,\n",
    "#        post_tick_handler=None\n",
    "#     )\n",
    "    print\n",
    "    print('##### Item', item)\n",
    "    print('S&S:')\n",
    "    print('IG.slist', IG.slist)\n",
    "    print('IG.sce', IG.sce)\n",
    "    #print('IG.sce.Status', IG.sce.Status)\n",
    "    #print('IG.sce',) \n",
    "    IG.setup()\n",
    "    IG.Vital2Symptom()\n",
    "    IG.update()\n",
    "    print('IG.sce', IG.sce)\n",
    "    \n",
    "#    print(\"IG: \", IG.sce.Status)\n",
    "#     for i in blackboard.Inters:\n",
    "#             print(\"BB S&S: \", i)\n",
    "    #print(\"IG: \", IG.sce.Status)\n",
    "#     print(\"SCE.concepts: \", IG.sce.concepts) #Empty []\n",
    "#     print(\"VCE.concepts: \", IG.vce.concepts) #Empty []\n",
    "#    IG.sce.DisplayStatus()\n",
    "    #print('Vital:')\n",
    "#     IG.vce.DisplayStatus()\n",
    "#    print(\"IG VCE status: \", IG.vce.Status)\n",
    "    #print('Inters:')\n",
    "    #IG.ice.DisplayStatus()\n",
    "    #print(\"IG SCE Status: \", IG.sce.Status)\n",
    "    #print(\"TC: \", TC)\n",
    "    #print(\"V: \", V)\n",
    "    #print(\"blackboard.TV\", blackboard.TV)\n",
    "    pt = i\n",
    "    #test_vec.append(blackboard.TV)\n",
    "    #with open('test_vec.txt', 'w') as f:\n",
    "       # pickle.dump(blackboard.TV, f)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check initial\n",
      "{'epinephrine': <ConceptExtract.PatientStatus object at 0x7f3dcb7cebd0>, 'bizarre behavior': <ConceptExtract.PatientStatus object at 0x7f3e219c7790>, 'violent': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce950>, 'nitroglycerin': <ConceptExtract.PatientStatus object at 0x7f3e219c7750>, 'rigidity': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce090>, 'rhonchi': <ConceptExtract.PatientStatus object at 0x7f3dcb7cee50>, 'fentanyl': <ConceptExtract.PatientStatus object at 0x7f3e219c7a90>, 'midazolam': <ConceptExtract.PatientStatus object at 0x7f3e219c77d0>, 'rash': <ConceptExtract.PatientStatus object at 0x7f3dcb7cea90>, 'substance abuse history': <ConceptExtract.PatientStatus object at 0x7f3dcb145050>, 'absent femoral pulses': <ConceptExtract.PatientStatus object at 0x7f3e219c7d50>, 'cool skin': <ConceptExtract.PatientStatus object at 0x7f3e219c79d0>, 'use of accessory muscles': <ConceptExtract.PatientStatus object at 0x7f3e219c7650>, 'lightheadedness': <ConceptExtract.PatientStatus object at 0x7f3e219c7090>, 'weakness': <ConceptExtract.PatientStatus object at 0x7f3e219c7810>, 'cpap': <ConceptExtract.PatientStatus object at 0x7f3dcb7ced10>, 'homicidal thoughts': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce990>, 'sleepiness': <ConceptExtract.PatientStatus object at 0x7f3e219c7590>, 'pin point pupils': <ConceptExtract.PatientStatus object at 0x7f3e219c7410>, 'malaise': <ConceptExtract.PatientStatus object at 0x7f3e219c7150>, 'hallucinations': <ConceptExtract.PatientStatus object at 0x7f3dcb1456d0>, 'loss of consciousness': <ConceptExtract.PatientStatus object at 0x7f3e219c7290>, 'nausea': <ConceptExtract.PatientStatus object at 0x7f3dcb145f90>, 'oxygen': <ConceptExtract.PatientStatus object at 0x7f3dcb145690>, 'hypoxemia': <ConceptExtract.PatientStatus object at 0x7f3e219c7cd0>, 'tenderness': <ConceptExtract.PatientStatus object at 0x7f3dcb145550>, 'dizziness': <ConceptExtract.PatientStatus object at 0x7f3e219c7b10>, 'pain severity': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce750>, 'constipation': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce5d0>, 'abdominal pain': <ConceptExtract.PatientStatus object at 0x7f3dcb7ceb10>, 'agitated delirium': <ConceptExtract.PatientStatus object at 0x7f3dcb7ceb50>, 'dysuria': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce550>, 'tripoding': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce610>, 'pale': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce890>, 'transport': <ConceptExtract.PatientStatus object at 0x7f3e219c7950>, 'vaginal bleeding': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce2d0>, 'incontinence': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce810>, 'mental status changes': <ConceptExtract.PatientStatus object at 0x7f3dcb145b90>, 'vaginal discharge': <ConceptExtract.PatientStatus object at 0x7f3e219c7b90>, 'distension': <ConceptExtract.PatientStatus object at 0x7f3dcb145950>, 'suicidal thought': <ConceptExtract.PatientStatus object at 0x7f3e219c7350>, 'trauma': <ConceptExtract.PatientStatus object at 0x7f3e219c74d0>, 'normal saline': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce9d0>, 'convulsions': <ConceptExtract.PatientStatus object at 0x7f3dcb7cedd0>, 'oral glucose': <ConceptExtract.PatientStatus object at 0x7f3e219c78d0>, 'myalgias': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce4d0>, 'confusion': <ConceptExtract.PatientStatus object at 0x7f3e219c7610>, 'combative': <ConceptExtract.PatientStatus object at 0x7f3dcb7cec90>, 'chest tightness': <ConceptExtract.PatientStatus object at 0x7f3e219c7050>, 'vomiting': <ConceptExtract.PatientStatus object at 0x7f3e219c7310>, 'delusional thoughts': <ConceptExtract.PatientStatus object at 0x7f3e219c7210>, 'cough': <ConceptExtract.PatientStatus object at 0x7f3e219c7250>, 'chest pressure': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce850>, 'dexamethasone': <ConceptExtract.PatientStatus object at 0x7f3dcb7ceb90>, 'ipratropium': <ConceptExtract.PatientStatus object at 0x7f3e219c7ed0>, 'hypoglycemia': <ConceptExtract.PatientStatus object at 0x7f3e219c75d0>, 'magnesium sulfate': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce050>, 'ondansetron': <ConceptExtract.PatientStatus object at 0x7f3e219c7910>, 'pain jaw': <ConceptExtract.PatientStatus object at 0x7f3e219c7510>, 'hypothermia': <ConceptExtract.PatientStatus object at 0x7f3e219c73d0>, 'glucagon': <ConceptExtract.PatientStatus object at 0x7f3dcb7cef10>, 'seizure': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce790>, 'pregnancy': <ConceptExtract.PatientStatus object at 0x7f3e219c70d0>, 'hyperglycemia': <ConceptExtract.PatientStatus object at 0x7f3e219c7dd0>, 'albuterol': <ConceptExtract.PatientStatus object at 0x7f3e219c7e90>, 'paraphernalia': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce0d0>, 'hyperthermia': <ConceptExtract.PatientStatus object at 0x7f3dcb145290>, 'wheezing': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce650>, 'tachycardia': <ConceptExtract.PatientStatus object at 0x7f3e219c7390>, 'aspirin': <ConceptExtract.PatientStatus object at 0x7f3e219c7b50>, 'narcan': <ConceptExtract.PatientStatus object at 0x7f3e219c7f50>, 'pain region': <ConceptExtract.PatientStatus object at 0x7f3e219c7890>, 'blindness': <ConceptExtract.PatientStatus object at 0x7f3e219c7f10>, 'post-ictal': <ConceptExtract.PatientStatus object at 0x7f3e219c7710>, 'hypotension': <ConceptExtract.PatientStatus object at 0x7f3e219c7ad0>, 'clammy skin': <ConceptExtract.PatientStatus object at 0x7f3e219c7c50>, 'baseline neurological status': <ConceptExtract.PatientStatus object at 0x7f3e219c7190>, 'dextrose': <ConceptExtract.PatientStatus object at 0x7f3e219c7450>, 'decreased mental status': <ConceptExtract.PatientStatus object at 0x7f3e219c7a10>, 'palpitations': <ConceptExtract.PatientStatus object at 0x7f3e219c7850>, 'rebound tenderness': <ConceptExtract.PatientStatus object at 0x7f3dcb145b10>, 'headache': <ConceptExtract.PatientStatus object at 0x7f3e219c76d0>, 'agitation': <ConceptExtract.PatientStatus object at 0x7f3e219c7690>, 'pain radiation': <ConceptExtract.PatientStatus object at 0x7f3e219c7a50>, 'dysrhythmia': <ConceptExtract.PatientStatus object at 0x7f3dcb145790>, 'hypertension': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce710>, 'bradypnea': <ConceptExtract.PatientStatus object at 0x7f3dcb145d10>, 'diazepam': <ConceptExtract.PatientStatus object at 0x7f3e219c7550>, 'last known well': <ConceptExtract.PatientStatus object at 0x7f3dcb7cef90>, 'diarrhea': <ConceptExtract.PatientStatus object at 0x7f3e219c7490>, 'unequal femoral pulses': <ConceptExtract.PatientStatus object at 0x7f3e219c7f90>, 'anxiety': <ConceptExtract.PatientStatus object at 0x7f3e219c7e50>, 'tachypnea': <ConceptExtract.PatientStatus object at 0x7f3e219c7bd0>, 'decreased visual acuity': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce510>, 'fever': <ConceptExtract.PatientStatus object at 0x7f3dcb7cec50>, 'abuse of substance': <ConceptExtract.PatientStatus object at 0x7f3e219c7d10>, 'rales': <ConceptExtract.PatientStatus object at 0x7f3e219c7d90>, 'tonic-clonic': <ConceptExtract.PatientStatus object at 0x7f3e219c7990>, 'morphine': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce290>, 'pain chest wall': <ConceptExtract.PatientStatus object at 0x7f3dcb7cef50>, 'shortness of breath': <ConceptExtract.PatientStatus object at 0x7f3dcb1453d0>, 'diaphoresis': <ConceptExtract.PatientStatus object at 0x7f3e219c72d0>, 'chest pain': <ConceptExtract.PatientStatus object at 0x7f3e219c7110>, 'bradycardia': <ConceptExtract.PatientStatus object at 0x7f3dcb7ce690>}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import ConceptExtract as CE\n",
    "ObjConcept = CE.ConceptExtractor(\"concept_list(s&s)_revised.csv\")\n",
    "ObjConcept.StatusInit()\n",
    "ObjConcept.ConceptExtract(test_narratives[1])\n",
    "ObjConcept.concepts\n",
    "print(ObjConcept.concepts)\n",
    "ObjConcept.FirstExtract(test_narratives[1],1)\n",
    "ObjConcept.concepts\n",
    "print(ObjConcept.concepts)\n",
    "#CE.CEWithoutMM(\"/renewconceptlists/All_In_One_signs&symptoms.xlsx\",\"\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_vec_list.txr','w') as fo:\n",
    "    pickle.dump(test_vec, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_vec_list.txr') as fo:\n",
    "    test_vec = pickle.load(fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_vec and test_vec hold the signs and symptoms extracted using ConceptExtract.py and behvaiours\n",
    "\n",
    "#-what are test and train_vec exactly???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to also include extraction using newest code from github\n",
    "# ie ConceptExtract.py ... behvaiours_m.py and all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then do S&S concept extract using w and w/o metamap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-d178aa4ecb66>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-d178aa4ecb66>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    help(Blackboard)p\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "help(Blackboard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "narra,intdict = load_RAA_data('./RAA_train.xlsx')\n",
    "test_narra, _ = load_RAA_data('./RAA_1000_test.xlsx', cv = False)\n",
    "risk_route = './Intervention Safety Sheet.xlsx'\n",
    "df_risk = pd.read_excel(risk_route)\n",
    "int2fn_score = dict()\n",
    "int2fp_score = dict()\n",
    "for row in df_risk.iterrows():\n",
    "    name = row[1]['Intervention'].split('\\'')[1]\n",
    "    FN_score, FP_score = 0, 0\n",
    "    if not pd.isnull(row[1]['If NOT Done When Indicated']):\n",
    "        FN_score = int(row[1]['If NOT Done When Indicated'])\n",
    "    if not pd.isnull(row[1]['If Done When NOT Indicated']):\n",
    "        FP_score = int(row[1]['If Done When NOT Indicated'])\n",
    "    if not FN_score or not FP_score or (name not in intdict):\n",
    "        continue\n",
    "    int2fn_score[name] = FN_score\n",
    "    int2fp_score[name] = FP_score\n",
    "int2num = dict()\n",
    "num2int = dict()\n",
    "for i,key in enumerate(int2fn_score):\n",
    "    int2num[key] = i\n",
    "    num2int[i] = key\n",
    "# n = NLP()\n",
    "# load technical n-grams\n",
    "# fo = open('ngrams.txt')\n",
    "# ngrams = set()\n",
    "# for line in fo:\n",
    "#     if line == '\\n': continue\n",
    "#     ngrams.add(line.strip('\\n'))\n",
    "# fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_safety = [dict() for _ in range(len(int2num))]\n",
    "for idx in range(len(num2int)):\n",
    "    inter_safety[idx][0] = 1. / int2fn_score[num2int[idx]]\n",
    "    inter_safety[idx][1] = 1. / int2fp_score[num2int[idx]]\n",
    "inter_safety_dic = dict()\n",
    "for idx in range(len(num2int)):\n",
    "    inter_safety_dic[idx] = int2fp_score[num2int[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_text = [i.text for i in narra]\n",
    "total_inter = [i.inter for i in narra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,_ = train_test_split(narra, random_state=46, test_size=.2, shuffle=True)\n",
    "train_text = [i.text for i in train]\n",
    "train_inter = [i.inter for i in train]\n",
    "test_text = [i.text for i in test_narra]\n",
    "test_inter = [i.inter for i in test_narra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [u'abov', u'afterward', u'alon', u'alreadi', u'alway', u'ani', u'anoth', u'anyon', u'anyth', u'anywher', u'becam', u'becaus', u'becom', u'befor', u'besid', u'cri', u'describ', u'dure', u'els', u'elsewher', u'empti', u'everi', u'everyon', u'everyth', u'everywher', u'fifti', u'forti', u'henc', u'hereaft', u'herebi', u'howev', u'hundr', u'inde', u'mani', u'meanwhil', u'moreov', u'nobodi', u'noon', u'noth', u'nowher', u'onc', u'onli', u'otherwis', u'ourselv', u'perhap', u'pleas', u'sever', u'sinc', u'sincer', u'sixti', u'someon', u'someth', u'sometim', u'somewher', u'themselv', u'thenc', u'thereaft', u'therebi', u'therefor', u'togeth', u'twelv', u'twenti', u'veri', u'whatev', u'whenc', u'whenev', u'wherea', u'whereaft', u'wherebi', u'wherev', u'whi', u'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = cleanPunc(text)\n",
    "    text = keepAlpha(text)\n",
    "    text = stemming(text)\n",
    "    return text\n",
    "\n",
    "#\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1), preprocessor = preprocess, stop_words = 'english', norm='l2')\n",
    "vectorizer.fit(train_text)\n",
    "x_train = vectorizer.transform(train_text)\n",
    "y_train = [[int2num[inter] for inter in case if inter in int2num] for case in train_inter]\n",
    "encoded_y_train = np.array([[int(num in case) for num in range(len(int2num))] for case in y_train])\n",
    "x_test = vectorizer.transform(test_text)\n",
    "y_test = [[int2num[inter] for inter in case if inter in int2num] for case in test_inter]\n",
    "encoded_y_test = np.array([[int(num in case) for num in range(len(int2num))] for case in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,1), preprocessor = preprocess, stop_words = 'english', norm='l2')\n",
    "vectorizer.fit(total_text)\n",
    "x_total = vectorizer.transform(total_text)\n",
    "y_total = [[int2num[inter] for inter in case if inter in int2num] for case in total_inter]\n",
    "encoded_y_total = np.array([[int(num in case) for num in range(len(int2num))] for case in y_total])\n",
    "class_weight = np.sum(encoded_y_total, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'precision_weighted': make_scorer(weighted_precision, weight = class_weight),\n",
    "           'recall_weighted': make_scorer(weighted_recall, weight = class_weight),\n",
    "           'f1_weighted': make_scorer(weighted_f1, weight = class_weight),\n",
    "           'precision_micro': 'precision_micro',\n",
    "           'recall_micro': 'recall_micro',\n",
    "           'f1_micro': 'f1_micro'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_table = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-c2436054f34b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf_16\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m scores_16 = cross_validate(clf_16, train_vec, encoded_y_total, scoring=scoring,\n\u001b[0;32m----> 4\u001b[0;31m                          cv=5, n_jobs=-1, return_train_score=False, return_estimator=True)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mshow_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 241\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/site-packages/sklearn/externals/joblib/externals/loky/_base.pyc\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    426\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# clfs using feature vectors\n",
    "clf_16 = OneVsRestClassifier(SVC(kernel = 'linear', probability=True))\n",
    "scores_16 = cross_validate(clf_16, train_vec, encoded_y_total, scoring=scoring,\n",
    "                         cv=5, n_jobs=-1, return_train_score=False, return_estimator=True)\n",
    "show_results(scores_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_16 = OneVsRestClassifier(SVC(kernel = 'linear', probability=True))\n",
    "clf_16.fit(train_vec, encoded_y_total)\n",
    "y_pre_16 = clf_16.predict(test_vec)\n",
    "y_pos_16 = clf_16.predict_proba(test_vec)\n",
    "show_test_results(encoded_y_test, y_pre_16, y_pos_16, class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_precision_weighted:0.63\n",
      "test_recall_weighted:0.61\n",
      "test_f1_weighted:0.58\n",
      "test_precision_micro:0.79\n",
      "test_recall_micro:0.60\n",
      "test_f1_micro:0.68\n"
     ]
    }
   ],
   "source": [
    "clf_rf_6 = RandomForestClassifier()\n",
    "scores_17 = cross_validate(clf_rf_6, train_vec, encoded_y_total, scoring=scoring,\n",
    "                         cv=5, n_jobs=-1, return_train_score=False, return_estimator=True)\n",
    "show_results(scores_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1000, 4]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-a3cfa271ef10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pre_17\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_rf_6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pos_17\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_rf_6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mshow_test_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_y_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pre_17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pos_17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-5201d5d9af1f>\u001b[0m in \u001b[0;36mshow_test_results\u001b[0;34m(gt, res, prob, class_weight)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_test_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"precision_micro\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m':'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"recall_micro\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m':'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"f1_micro\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m':'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1270\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tay/anaconda3/envs/py2_NIST/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 4]"
     ]
    }
   ],
   "source": [
    "clf_rf_6 = RandomForestClassifier()\n",
    "clf_rf_6.fit(train_vec, encoded_y_total)\n",
    "y_pre_17 = clf_rf_6.predict(test_vec)\n",
    "y_pos_17 = clf_rf_6.predict_proba(test_vec)\n",
    "show_test_results(encoded_y_test, y_pre_17, trans_prob(y_pos_17), class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt_6 = DecisionTreeClassifier()\n",
    "scores_18 = cross_validate(clf_dt_6, train_vec, encoded_y_total, scoring=scoring,\n",
    "                         cv=5, n_jobs=-1, return_train_score=False, return_estimator=True)\n",
    "show_results(scores_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt_6 = DecisionTreeClassifier()\n",
    "clf_dt_6.fit(train_vec, encoded_y_total)\n",
    "y_pre_18 = clf_dt_6.predict(test_vec)\n",
    "y_pos_18 = clf_dt_6.predict_proba(test_vec)\n",
    "show_test_results(encoded_y_test, y_pre_18, trans_prob(y_pos_18), class_weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
